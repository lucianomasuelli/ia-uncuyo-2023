# Fundamentos filosóficos
Folósofos desde ya hace varios años han buscado la respuesta a preguntas relacionadas con el funcioamiento de la mente humana, la consciencia, inteligencia 
y la discusión sobre si una máquina puede ser capaz de imitar nuestra mente.
## Inteligencia Artificial débil
Esta hipótesis plantea que la Inteligencia Artificial podría comportarse como si fuese inteligente, pero sin poseer verdadera inteligencia.
Por lo tanto, surge la gran interrogante: ¿Pueden las máquinas pensar? Dijkstra compara este cuestionamiento con la pregunta de si un submarino puede nadar,
y sostiene que aún no se ha alcanzado una definición precisa de lo que implica la palabra "pensar".
En 1950, Alan Turing propuso que en lugar de indagar si las máquinas pueden pensar, deberíamos cuestionar si pueden superar una prueba de
inteligencia conductual, conocida como el célebre Test de Turing. Este test implica que un programa sostenga una conversación con un interrogador humano
durante 5 minutos, y este último deba determinar si está interactuando con un programa o con un ser humano. El programa supera la prueba si logra engañar al interrogador
en un 30% de los casos.

Existen variados argumentos que niegan la posibilidad de máquinas inteligentes, a continuación se muestran algunos.

### El argumento de la discapacidad
Este argumento lista una serie de acciones relacionadas con comportamientos humanos que una máquina supuestamente nunca será capaz de hacer. Pero con el tiempo
se ha demostrado que las máquinas pueden desarrollar varias de estas acciones o actividades teniendo incluso un mejor desempeño que los humanos.  
Esto no significa que las computadoras tengan una comprensión o realmente entiendan la tarea que están realizando, no tiene que ver con su comportamiento. 
En general se tiene una concepción erronea sobre los procesos mentales que se requieren para producir un comportamiento.

### La objeción matemática
Turing y Gödel han demostrado que hay ciertos problemas matematicos que en principio son insolubles por los sistemas formales que representan a las máquinas.
Algunos filósofos argumentan que las máquinas son mentalmente inferiores a los humanos ya que son sistemas formales limitados por el "incompleteness theorem" 
mientras que los humanos no tenemos esa limitación.  
Este argumento es refutable observando que en primer lugar Gödel asume que las computadoras son Máquinas de Turing, pero no tiene en cuenta que las Máquinas de
Turing son infinitas, mientras que las computadoras no lo son y, por lo tanto, cualquier computadora puede describirse como un sistema (muy grande) en 
lógica proposicional, que no está sujeto al teorema de incompletitud de Gödel.  
Por otro lado se puede demostrar que hay problemas que un humano no podría resolver en su tiempo de vida, pero una computadora podría hacerlo en cuestión de segundos. 
Esto evidencia que a la hora de definir la inteligencia, el razonamiento matemático formal juega un papel secundario.  
También es importante destacar que estas limitaciones matemáticas que presentan las computadoras podrían ser también limitaciones para nosotros, ya que no se 
puede demostrar formalmente nuestro _talento humano_.

### El argumento de la informalidad
Propone que la IA presenta el _**problema de la calificación**_, sosteniendo que el comportamiento humano es demasiado complejo como para que un simple conjunto 
de reglas pueda capturarlo, y como las computadoras no hacen mas que seguir conjuntos de reglas, entonces no pueden generar un comportamiento tan inteligente 
como el de los humanos.
La posición que se critica principalmente por el filósofo Hubert Dreyfus llegó a ser llamada _"Good Old-Fashioned AI"_ o GOFAI en el que sostiene que los agentes lógicos que razonan a partir de conjuntos de hechos y reglas que describen su domino, son vulnerables al problema de la clasificación. La crítica de Dreyfus, por lo tanto, no va dirigida contra las computadoras en sí, sino más bien contra una manera particular de programarlas.  
Bajo la perspectiva de Dreyfus, la experiencia humana incluye el conocimiento de algunas reglas, pero solamente como un "contexto holístico" o "trasfondo" dentro del cual operan los seres humanos.

Dreyfus y Dreyfus en 1986 proponen una arquitectura de red neuronal organizada en una gran biblioteca de casos, pero señalan varios problemas:
1. No se puede conseguir una buena generalización a partir de ejemplos sin conocimiento previo o "background knowledge". Según ellos, no se sabe como
incorparar este conocimiento a los procesos de aprendizaje de las redes neuronales.
2. Según ellos no se puede lograr un aprendizaje no asistido.
3. Los algoritmos de aprendizaje no tienen un buen rendimiento con muchas características, y si seleccionamos un subconjunto de características, "no existe una forma conocida de agregar nuevas características en caso de que el conjunto actual resulte insuficiente para explicar los hechos aprendidos".
4. El cerebro es capaz de dirigir sus sensores para buscar información relevante y procesarla para extraer aspectos pertinentes a la situación actual. Sin embargo, Dreyfus y Dreyfus afirman: "Actualmente, no se entienden detalles de este mecanismo ni siquiera se han formulado hipótesis de manera que pudieran guiar la investigación en IA".

Estos problemas con el paso del tiempo han sido abordados y hoy en día se han solucionado total o parcilmente cada uno de ellos.  
Dreyfus también argumenta el concepto de la _cognición encarnada_ sostiene que no tiene sentido considerar el cerebro por separado: la cognición ocurre dentro de un cuerpo, que está integrado en un entorno. Necesitamos estudiar el sistema en su totalidad.

## Inteligencia Artificial fuerte
Este concepto se refiere a la afirmación de que las IA podrían llegar a pensar como lo hace un ser humano, tener consciencia y no sólo ser una simulación del pensamiento.  
Muchos filósofos piensan que el hecho de que una máquina pase la Prueba de Turing no es sificiente para afirmar que esta está realmente pensando. De hecho el mismo Turing llama argumento de la **consciencia** a la afirmación de que la máquina debe ser consciente de sus propios estados mentales y acciones. Otros dos puntos de vista son la **fenomenología**, o el estudio de la experiencia directa: la máquina debe realmente sentir emociones y  la **intencionalidad**, es decir, la pregunta de si las supuestas creencias, deseos y otras representaciones de la máquina son realmente "acerca" de algo en el mundo real.  
Según Turing, en algún momento futuro el diálogo entre hombres y máquinas será algo diario y común, haciendo que las personas dejen de marcar una distinción entre 
mentes reales o artificiales, ensamblando ambas ideas en un único concepto de la mente.  

Entre medio de estas dicuciones tambien surge el **problema mente-cuerpo** en el que el argumento principal habla de que las mentes de los humanos son "reales" y 
las de las máquinas pueden o no serlo. Es decir, se trata de entender cómo es que los humanos tienen mentes reales, no solo cuerpos que generan procesos neurofisiológicos. Y esto va de la mano con la pregunta de si las máquinas pueden tener mentes reales.  
A partir de estas preguntas surgen dos posiciones principales:
- **Dualismo**: considera que la actividad mental del pensamiento y los procesos físicos del cuerpo deben existir en distintos reinos. El problema mente-cuerpo al que se enfrentan los dualistas es la pregunta de cómo la mente puede controlar el cuerpo si ambos son realmente separados.
- **Monismo**: tambien llamado **fisicalismo**, postula que la mente no está separada del cuerpo, y que los _estados mentales_ son estados físicos.

### Estados mentales
Se ha tratado de explicar que significa que una persona (o una computadora) se encuentre en un estado mental específico. Se han centrado especialmente en los estados intencionales. Estos son estados, como creer, saber, desear, temer, y así sucesivamente, que hacen referencia a algún aspecto del mundo exterior.  
Si el fisicalismo es correcto, debe ser el caso que la descripción adecuada del estado mental de una persona esté determinada por el estado cerebral de esa persona.
Por lo tanto se plantea que hay distintas clases de estados mentales de las que derivan instancias para distintos casos particulares.  
Para desafiar estas ideas se han hecho algunos experimentos mentales como puede ser el del **cerebro en el tanque**: imagina que el que el cerebro de una persona se separa de su cuerpo al nacer y se coloca en un tanque. En este escenario, el cerebro recibe señales electrónicas de una simulación de un mundo ficticio y envía señales motoras que modifican esa simulación. Teniendo en cuenta que la vida simulada es idéntica a la que la persona habría vivido en el mundo real,a pesar de tener un estado cerebral idéntico al de alguien que está comiendo una hamburguesa real, no se puede decir que la persona tiene el estado mental de "saber que está comiendo una hamburguesa" porque nunca ha tenido una experiencia real de una hamburguesa. Se plantea así un desafío a la simplicidad de la idea de que el estado mental está determinado únicamente por el estado cerebral.  
Este ejemplo parece contradecir la perspectiva de que los estados cerebrales determinan los estados mentales. Una forma de resolver este dilema es afirmar que el contenido de los estados mentales puede ser interpretado desde dos puntos de vista diferentes. La visión del _contenido amplio_ lo interpreta desde el punto de vista de un observador externo omnisciente con acceso a toda la situación, que puede distinguir las diferencias en el mundo. Bajo esta perspectiva, el contenido de los estados mentales implica tanto el estado cerebral como la historia del entorno. Por otro lado, el _contenido estrecho_ considera solo el estado cerebral.  
El _contenido amplio_ es completamente apropiado si uno tiene como objetivo atribuir estados mentales a otros que comparten su mundo, predecir su comportamiento probable y sus efectos, etc. Por otro lado, si uno se preocupa por la pregunta de si los sistemas de IA realmente están pensando y realmente tienen estados mentales, entonces el _contenido estrecho_ es apropiado.

### Funcionalismo
La teoría del funcionalismo sostiene que un estado mental es cualquier condición causal intermedia entre la entrada y la salida. Según la teoría funcionalista, cualquier dos sistemas con procesos causales isomórficos tendrían los mismos estados mentales. Por lo tanto, un programa de computadora podría tener los mismos estados mentales que una persona.  
Para ilustrar esto se planteó un experimento mental con un escenario hipotético en el que en el que se reemplazan gradualmente todas las neuronas en el cerebro de una persona por dispositivos electrónicos que imitan su comportamiento, sin interrumpir el funcionamiento general del cerebro. Se analiza la preocupación por cómo esto afectaría tanto el comportamiento externo como la experiencia interna del individuo. Algunos creen que la conciencia permanecería intacta, mientras que otros argumentan que desaparecería a medida que el proceso avanza. La discusión refleja un conflicto de intuiciones sobre el papel de la conciencia en relación con el funcionamiento cerebral y el comportamiento observable.

### Naturalismo Biológico
Según esta perspectiva planteada por Jhon Searle, los estados mentales son características emergentes de alto nivel que son causadas por procesos físicos de bajo nivel en las neuronas, y son las propiedades no especificadas de las neuronas las que importan. Por lo tanto, los estados mentales no pueden ser duplicados simplemente en función de una estructura funcional similar con el mismo comportamiento de entrada y salida; se requeriría que el programa se ejecute en una arquitectura con el mismo poder causal que las neuronas. Su conclusión es que ejecutar el programa adecuado (es decir, producir las salidas correctas) no es una condición suficiente para tener una mente.

### Conciencia
De todos los debates que se presentan sobre la IA, el tema central es el de la conciencia. Un enfoque es la cuestión de la experiencia subjetiva, es decir, por qué se siente algo al tener ciertos estados cerebrales (por ejemplo, al comer una hamburguesa), mientras que presumiblemente no se siente nada al tener otros estados físicos (por ejemplo, al ser una roca). Se utiliza el término técnico "qualia" para referirse a la naturaleza intrínseca de las experiencias.  
La conciencia es un desafío no solo para el funcionalismo, sino también para la ciencia en general. Aunque se pueden comprender los procesos neuronales y sus transformaciones moleculares, no existe una forma aceptada actualmente de razonar desde esos hallazgos hasta la conclusión de que el ente que posee esas neuronas tiene una experiencia subjetiva particular. Esta brecha explicativa ha llevado a algunos filósofos a concluir que los humanos son incapaces de comprender adecuadamente su propia conciencia.  

Turing sugiere que aunque la cuestión de la conciencia es un misterio, no es necesario resolverlo para avanzar en la creación de programas de IA inteligentes. Su enfoque principal es desarrollar programas que se comporten de manera inteligente, y la cuestión de hacerlos conscientes no es un proyecto que estén dispuestos a abordar, ni uno cuyo éxito puedan determinar.

## La ética y los riesgos de desarrollar Inteligencia Artificial
Antes de desarrollar alguna tecnología nueva o progresar en algun proyecto como es la IA, se deben analizar los efectos negativos o riesgos que esta puede traer y 
en base a esto decidir si realmente es ético avanzar con el trabajo.  
La Inteligencia Artificial trae algunos problemas que se deben considerar y tratar de la mejor manera para poder incluir estas tecnologías en nuestra sociedad:
- Las personas podrían perder sus empleos debido a la automatización.
- Las personas podrían tener demasiado (o muy poco) tiempo libre.
- Las personas podrían perder su sentido de ser únicas.
- Los sistemas de IA podrían ser utilizados para fines indeseables.
- El uso de sistemas de IA podría resultar en una pérdida de responsabilidad.
- El éxito de la IA podría significar el fin de la raza humana.

![Fundamentos Filosóficos](https://github.com/lucianomasuelli/ia-uncuyo-2023/assets/83616746/fa35e77c-e136-4f60-a833-bf6b05553a0c)

## Discusión
Personalmente, considero que los temas abordados en este texto son de suma importancia, especialmente en el contexto actual de avance tecnológico. Coincido con la postura de Turing cuando afirma que definir si una máquina es consciente o no puede resultar una tarea imposible, y que nuestro enfoque principal debería ser lograr que estas máquinas se comporten de manera inteligente. También comparto la idea de que en un futuro cercano, la línea que separa a las personas de las máquinas se desdibujará gradualmente, y las veremos como entidades que piensan de manera similar a nosotros. Aunque se pueda demostrar que una máquina no piensa como nosotros, esto no debe impedir que una persona sienta que está interactuando con un ser consciente al dialogar con una máquina.  
En cuanto a los temas relacionados con la ética, hoy en día ya podemos observar cómo varios de los puntos mencionados se están materializando. Si bien es cierto que algunos empleos pueden perderse debido a la automatización, esto conlleva la aparición de soluciones rápidas para nuevas tareas, lo que a su vez genera la creación de nuevos empleos. No obstante, el verdadero desafío radica en los usos maliciosos que estas tecnologías pueden tener, y es crucial concienciar a la población al respecto. Es innegable que existe un riesgo inherente, pero con una mayor educación y conciencia, podemos mitigar estos peligros.  
En última instancia, creo que si al desarrollar nuevas tecnologías se exploran cuidadosamente todas las posibles variantes y se consideran todas las posibilidades, no deberíamos llegar a un escenario distópico en el que las máquinas se vuelvan en contra de la humanidad. Es esencial abordar estos desafíos con responsabilidad y un enfoque ético para asegurar un futuro donde la tecnología sirva para el bienestar de la sociedad en lugar de perjudicarla.

## Comentario sobre artículo "You Are Not a Parrot"
La inteligencia artificial generativa es solo una pequeña muestra de la ola de cambios y ventajas que podemos aprovechar. En mi experiencia reciente, he experimentado un cambio radical tanto en mi enfoque de estudio como en mi desempeño laboral.
Sin embargo, es importante tener en cuenta, como se menciona en el texto, que estas IA son como loros que repiten combinaciones de palabras que su algoritmo considera adecuadas. A pesar de esto, han demostrado ser altamente efectivas al proporcionar respuestas precisas en una amplia gama de temas. Estas nuevas herramientas nos ofrecen soluciones rápidas y eficaces para problemas que antes requerían una considerable inversión de tiempo y energía. 

