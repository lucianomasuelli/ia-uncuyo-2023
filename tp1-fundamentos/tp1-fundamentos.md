# Fundamentos filosóficos
Folósofos desde ya hace varios años han buscado la respuesta a preguntas relacionadas con el funcioamiento de la mente humana, la consciencia, inteligencia 
y la discusión sobre si una máquina puede ser capaz de imitar nuestra mente.
## Inteligencia Artificial débil
Esta hipótesis plantea que la Inteligencia Artificial podría comportarse como si fuese inteligente, pero sin poseer verdadera inteligencia.
Por lo tanto, surge la gran interrogante: ¿Pueden las máquinas pensar? Dijkstra compara este cuestionamiento con la pregunta de si un submarino puede nadar,
y sostiene que aún no se ha alcanzado una definición precisa de lo que implica la palabra "pensar".
En 1950, Alan Turing propuso que en lugar de indagar si las máquinas pueden pensar, deberíamos cuestionar si pueden superar una prueba de
inteligencia conductual, conocida como el célebre Test de Turing. Este test implica que un programa sostenga una conversación con un interrogador humano
durante 5 minutos, y este último deba determinar si está interactuando con un programa o con un ser humano. El programa supera la prueba si logra engañar al interrogador
en un 30% de los casos.

Existen variados argumentos que niegan la posibilidad de máquinas inteligentes, a continuación se muestran algunos.

### El argumento de la discapacidad
Este argumento lista una serie de acciones relacionadas con comportamientos humanos que una máquina supuestamente nunca será capaz de hacer. Pero con el tiempo
se ha demostrado que las máquinas pueden desarrollar varias de estas acciones o actividades teniendo incluso un mejor desempeño que los humanos.  
Esto no significa que las computadoras tengan una comprensión o realmente entiendan la tarea que están realizando, no tiene que ver con su comportamiento. 
En general se tiene una concepción erronea sobre los procesos mentales que se requieren para producir un comportamiento.

### La objeción matemática
Turing y Gödel han demostrado que hay ciertos problemas matematicos que en principio son insolubles por los sistemas formales que representan a las máquinas.
Algunos filósofos argumentan que las máquinas son mentalmente inferiores a los humanos ya que son sistemas formales limitados por el "incompleteness therem" 
mientras que los humanos no tenemos esa limitación.  
Este argumento es refutable observando que en primer lugar Gödel asume que las computadoras son Máquinas de Turing, pero no tiene en cuenta que las Máquinas de
Turing son infinitas, mientras que las computadoras no lo son y, por lo tanto, cualquier computadora puede describirse como un sistema (muy grande) en 
lógica proposicional, que no está sujeto al teorema de incompletitud de Gödel.  
Por otro lado se puede demostrar que hay problemas que un humano no podría resolver en su tiempo de vida, pero una computadora podría hacerlo en cuestión de segundos. 
Esto evidencia que a la hora de definir la inteligencia, el razonamiento matemático formal juega un papel secundario.  
También es importante destacar que estas limitaciones matemáticas que presentan las computadoras podrían ser también limitaciones para nosotros, ya que no se 
puede demostrar formalmente nuestro _talento humano_.

### El argumento de la informalidad
Propone que la IA presenta el _**problema de la calificación**_, sosteniendo que el comportamiento humano es demasiado complejo como para que un simple conjunto 
de reglas pueda capturarlo, y como las computadoras no hacen mas que seguir conjuntos de reglas, entonces no pueden generar un comportamiento tan inteligente 
como el de los humanos.
La posición que se critica principalmente por el filósofo Hubert Dreyfus llegó a ser llamada _"Good Old-Fashioned AI"_ o GOFAI en el que sostiene que los agentes lógicos que razonan a partir de conjuntos de hechos y reglas que describen su domino, son vulnerables al problema de la clasificación. La crítica de Dreyfus, por lo tanto, no va dirigida contra las computadoras en sí, sino más bien contra una manera particular de programarlas.  
Bajo la perspectiva de Dreyfus, la experiencia humana incluye el conocimiento de algunas reglas, pero solamente como un "contexto holístico" o "trasfondo" dentro del cual operan los seres humanos.

Dreyfus y Dreyfus en 1986 proponen una arquitectura de red neuronal organizada en una gran biblioteca de casos, pero señalan varios problemas:
1. No se puede conseguir una buena generalización a partir de ejemplos sin conocimiento previo o "background knowledge". Según ellos, no se sabe como
incorparar este conocimiento a los procesos de aprendizaje de las redes neuronales.
2. Según ellos no se puede lograr un aprendizaje no asistido.
3. Los algoritmos de aprendizaje no tienen un buen rendimiento con muchas características, y si seleccionamos un subconjunto de características, "no existe una forma conocida de agregar nuevas características en caso de que el conjunto actual resulte insuficiente para explicar los hechos aprendidos".
4. El cerebro es capaz de dirigir sus sensores para buscar información relevante y procesarla para extraer aspectos pertinentes a la situación actual. Sin embargo, Dreyfus y Dreyfus afirman: "Actualmente, no se entienden detalles de este mecanismo ni siquiera se han formulado hipótesis de manera que pudieran guiar la investigación en IA".

Estos problemas con el paso del tiempo han sido abordados y hoy en día se han solucionado total o parcilmente cada uno de ellos.  
Dreyfus también argumenta el concepto de la _cognición encarnada_ sostiene que no tiene sentido considerar el cerebro por separado: la cognición ocurre dentro de un cuerpo, que está integrado en un entorno. Necesitamos estudiar el sistema en su totalidad.

## Inteligencia Artificial fuerte
Este concepto se refiere a la afirmación de que las IA podrían llegar a pensar como lo hace un ser humano, tener consciencia y no sólo ser una simulación del pensamiento.
Muchos filósofos piensan que el hecho de que una máquina pase la Prueba de Turing no es sificiente para afirmar que esta esta realmente pensando. De ehcho el mismo Turing llama argumento de la consciencia a la afirmación 
de que la máquina debe ser consciente de sus propios estados mentales y acciones. Otros dos puntos de vista son la fenomenología, o el estudio de la experiencia directa: la máquina debe realmente sentir emociones y 
la intencionalidad, es decir, la pregunta de si las supuestas creencias, deseos y otras representaciones de la máquina son realmente "acerca" de algo en el mundo real.  


